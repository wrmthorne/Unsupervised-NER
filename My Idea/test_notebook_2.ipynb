{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from kmeans_pytorch import kmeans, kmeans_predict\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "The CoNLL2003 dataset is first used to evaluate performance. The ground truth ner tags are used only select named entities to allow the class allocation to be tested independently by assumung perfect extraction. Later work will be conducted into identifying which entities should be labelled. NER tags are mapped to a non-BIO based scheme to reduce the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/home/william/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f173e7b0a834cca9221de8798b797e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/william/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-e643d3196526a30f.arrow\n",
      "Loading cached processed dataset at /home/william/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-4ae7629d9bae3654.arrow\n",
      "Loading cached processed dataset at /home/william/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-d22db9ce0f6a945f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'ner_tags': [2, 0, 4, 0, 0, 0, 4, 0, 0], 'input_ids': [[101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102]], 'target_mask': [[0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "original_tags = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "# New non-BIO scheme\n",
    "new_tags = {0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 3, 6: 3, 7: 4, 8: 4}\n",
    "new_tags_string = {0: 'O', 1: 'PER', 2: 'ORG', 3: 'LOC', 4: 'MISC'}\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "\n",
    "def process_batch(example):\n",
    "    target_mask = torch.tensor([0], dtype=torch.int8)\n",
    "    input_ids = torch.tensor([101], dtype=int)\n",
    "\n",
    "    for token, ner_tag in zip(example['tokens'], example['ner_tags']):\n",
    "        encoded_tok = tokenizer.encode(token, return_tensors='pt')[0, 1:-1]\n",
    "\n",
    "        input_ids = torch.cat((input_ids, encoded_tok))\n",
    "        target_mask = torch.cat((target_mask, torch.full_like(encoded_tok, 1 if ner_tag != 0 else 0)))\n",
    "\n",
    "    target_mask = torch.cat((target_mask, torch.tensor([0]))).unsqueeze(0)\n",
    "    input_ids = torch.cat((input_ids, torch.tensor([102]))).unsqueeze(0)\n",
    "\n",
    "    return {'input_ids': input_ids, 'target_mask': target_mask}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    dataset[split] = dataset[split].map(lambda batch: {\n",
    "        **process_batch(batch),\n",
    "        'ner_tags': [new_tags[tag] for tag in batch['ner_tags']]\n",
    "        }).remove_columns(['id', 'chunk_tags'])\n",
    "\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Define a method to extract the context vectors of the extracted entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "def get_context_vectors(input_ids, attention_mask, target_mask):\n",
    "    # Ignore gradient to improve performance\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.to(device), attention_mask.to(device))\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "    # Extract model embeddings layer activations\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "    # Remove batches dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "    # Swap layer and token dimensions\n",
    "    token_embeddings = token_embeddings.permute(1, 0, 2)\n",
    "    \n",
    "    # Identify indices within encoded text to calculate context embeddings\n",
    "    target_indices = target_mask.to(device).nonzero()\n",
    "\n",
    "    # Use the sum of the last 4 embedding layers as an aggregation of context for the selected indices\n",
    "    stacked_token_embeddings = token_embeddings.repeat(torch.sum(target_mask), 1, 1, 1)\n",
    "    embedding_aggregate = torch.sum(stacked_token_embeddings[torch.arange(0, torch.sum(target_mask)), target_indices[:, 1], -4:], dim=1)\n",
    "\n",
    "    return embedding_aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all of the context vectors using the defined method on the training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Contexts: 100%|██████████| 14041/14041 [02:38<00:00, 88.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65030, 768])\n",
      "65030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "context_vectors = torch.empty(0, 768).to(device)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for example in tqdm(dataset['train'], desc='Collecting Contexts'):\n",
    "    input_ids = torch.tensor(example['input_ids'])\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    target_mask = torch.tensor(example['target_mask'])\n",
    "\n",
    "    embedding_aggregate = get_context_vectors(input_ids, attention_mask, target_mask)\n",
    "    context_vectors = torch.cat((context_vectors, embedding_aggregate))\n",
    "\n",
    "print(context_vectors.shape)\n",
    "print(sum(sum(x[0]) for x in dataset['train']['target_mask']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster\n",
    "\n",
    "Cluster context vectors using kmeans with $k = 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 39it [00:10,  3.60it/s, center_shift=0.000000, iteration=39, tol=0.000100]  \n"
     ]
    }
   ],
   "source": [
    "# Seeds for reproducing cluster centres\n",
    "torch.random.seed = 42\n",
    "torch.cuda.seed = 42\n",
    "np.random.seed(42)\n",
    "\n",
    "distance = 'cosine' # 'euclidean'\n",
    "\n",
    "cluster_ids, cluster_centres = kmeans(context_vectors, 4, distance=distance, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually evaluate clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on cuda..\n",
      "{'European': [3], 'Commission': [3], 'German': [3], 'British': [3]}\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "example = dataset['train'][i]\n",
    "\n",
    "input_ids = torch.tensor(example['input_ids'])\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "target_mask = torch.tensor(example['target_mask'])\n",
    "\n",
    "test_context_vectors = get_context_vectors(input_ids, attention_mask, target_mask)\n",
    "\n",
    "if len(test_context_vectors) == 1:\n",
    "    test_context_vectors = test_context_vectors.repeat(2, 1)\n",
    "\n",
    "test_cluster_ids = kmeans_predict(test_context_vectors, cluster_centres, distance=distance, device=device)\n",
    "test_clusters_ids_list = test_cluster_ids.squeeze().tolist()\n",
    "\n",
    "token_ids = {token: tokenizer.encode(token)[1:-1] for token, ner_tag in zip(example['tokens'], example['ner_tags']) if ner_tag != 0}\n",
    "token_predictions = {token: [test_clusters_ids_list.pop(0) for _ in range(len(ids))] for token, ids in token_ids.items()}\n",
    "\n",
    "print(token_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Calculate context vectors for all validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Contexts: 100%|██████████| 3250/3250 [00:36<00:00, 88.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16225, 768])\n",
      "16225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_context_vectors = torch.empty(0, 768).to(device)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for example in tqdm(dataset['validation'], desc='Collecting Contexts'):\n",
    "    input_ids = torch.tensor(example['input_ids'])\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    target_mask = torch.tensor(example['target_mask'])\n",
    "\n",
    "    embedding_aggregate = get_context_vectors(input_ids, attention_mask, target_mask)\n",
    "    val_context_vectors = torch.cat((val_context_vectors, embedding_aggregate))\n",
    "\n",
    "print(val_context_vectors.shape)\n",
    "print(sum(sum(x[0]) for x in dataset['validation']['target_mask']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify cluster allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on cuda..\n"
     ]
    }
   ],
   "source": [
    "val_cluster_ids = kmeans_predict(val_context_vectors, cluster_centres, distance=distance, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign cluster ids to each token in the dataset and obtain a single cluster id for items with multiple, i.e. words composed of sub-word level tokens, by taking the mode or majority vote. Using `max(set(lst), key=lst.count))` for majority voting yields the most frequent list item or, in the case that there is a tie for most frequent, the item with the lowest value:\n",
    "\n",
    "```python\n",
    "a = [1, 1, 1, 0, 0]\n",
    "b = [1, 1, 0, 0]\n",
    "max(set(a), key=a.count)\n",
    "# >> 1\n",
    "max(set(b), key=b.count)\n",
    "# >> 0\n",
    "```\n",
    "Another implementation may find that the head sub-word token is more informative.\n",
    "\n",
    "Also collect the ground truth NER tag for each entity for comparison. `Note`: The cluster id numbers will not correspond to the NER tag numbers. They are two sets of labels that need to be mapped to eachother in some way.\n",
    "\n",
    "Finally, find which mapping of cluster ids to NER ids yields the best f-1 performance. `Note`: This calculation does not consider entities that weren't tagged by using PROPN. This is to control for the initial entity extraction task which will be reviewed at another stage. This is to just evaluate whether this style of clustering is suitable for identifying entity classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3250/3250 [00:01<00:00, 2159.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'accuracy': 17.59851214692549, 'mapping': [(0, 1), (1, 2), (2, 3), (3, 4)]},\n",
      " {'accuracy': 5.579449029408346, 'mapping': [(0, 2), (1, 3), (2, 4), (3, 1)]},\n",
      " {'accuracy': 30.861327443914917, 'mapping': [(0, 3), (1, 4), (2, 1), (3, 2)]},\n",
      " {'accuracy': 45.96071137975125, 'mapping': [(0, 4), (1, 1), (2, 2), (3, 3)]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(cluster_ids):\n",
    "    sample_predictions = []\n",
    "\n",
    "    for example in tqdm(dataset['validation']):\n",
    "        token_ids = {f'{i}-{token}': {\n",
    "            'ids': tokenizer.encode(token)[1:-1],\n",
    "            'ner_tag': ner_tag\n",
    "        } for i, (token, ner_tag) in enumerate(zip(example['tokens'], example['ner_tags'])) if ner_tag != 0}\n",
    "\n",
    "        token_predictions = {token: {\n",
    "            'cluster_id': max(set((lst := [cluster_ids.pop(0) for _ in range(len(attributes['ids']))])), key=lst.count),\n",
    "            'ner_tag': attributes['ner_tag']\n",
    "        } for token, attributes in token_ids.items()}\n",
    "\n",
    "        sample_predictions.append(token_predictions)\n",
    "\n",
    "    mapping_freqs = Counter([(x_i['cluster_id'], x_i['ner_tag']) for x in sample_predictions for x_i in x.values()])\n",
    "    p = defaultdict(dict)\n",
    "\n",
    "    for k, v in mapping_freqs.items():\n",
    "        p[k[0]].update({k[1]: v})\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data=p, orient='index').sort_index()\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "    eye = np.eye(len(df.columns), dtype=bool)\n",
    "    total = np.sum(df.to_numpy().flatten())\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(df.columns)):\n",
    "        mapping = list(df[(df * np.roll(eye, i, axis=1)) != 0].stack().index)\n",
    "        accuracy = np.sum((df * np.roll(eye, i, axis=1)).to_numpy().flatten()) / total * 100\n",
    "        results.append({'mapping': mapping, 'accuracy': accuracy})\n",
    "\n",
    "    return results\n",
    "\n",
    "val_clusters_ids_list = val_cluster_ids.squeeze().tolist()\n",
    "results = evaluate(val_clusters_ids_list)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Masking\n",
    "\n",
    "Using a more testable implementation of the work in this notebook, explore variations on the original model to evaluate improvement. First import developed class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_vector_clustering import ContextClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the class to the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Collecting Contexts: 100%|██████████| 14041/14041 [02:40<00:00, 87.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 48it [00:12,  3.71it/s, center_shift=0.000000, iteration=48, tol=0.000100]  \n"
     ]
    }
   ],
   "source": [
    "X_fit = ContextClustering(random_state=42).fit(dataset['train'], masked_targets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Predict the class assignment of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Contexts: 100%|██████████| 3250/3250 [00:36<00:00, 90.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = X_fit.predict(dataset['validation'])\n",
    "y_hat_list = y_hat.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance in the same way as before. Masking the targetted tokens performed very badly - about random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3250/3250 [00:01<00:00, 2214.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'accuracy': 18.935255143554574, 'mapping': [(0, 1), (1, 2), (2, 3), (3, 4)]},\n",
      " {'accuracy': 25.525979309543185, 'mapping': [(0, 2), (1, 3), (2, 4), (3, 1)]},\n",
      " {'accuracy': 28.12972218993374, 'mapping': [(0, 3), (1, 4), (2, 1), (3, 2)]},\n",
      " {'accuracy': 27.4090433569685, 'mapping': [(0, 4), (1, 1), (2, 2), (3, 3)]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(y_hat_list)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Contexts:   0%|          | 0/3250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "torch.Size([9, 4, 768])\n",
      "torch.Size([9, 3072])\n",
      "=======\n",
      "torch.Size([9, 4, 768])\n",
      "torch.Size([9, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def cat_n_layers(n):\n",
    "    def aggregate(stacked_token_embeddings, target_indices):\n",
    "        return torch.cat([*stacked_token_embeddings[torch.arange(0, target_indices.size(0)), target_indices[:, 1], -n:].permute(1, 0, 2)], dim=1)\n",
    "\n",
    "    return aggregate\n",
    "\n",
    "def sum_n_layers(n):\n",
    "    def aggregate(stacked_token_embeddings, target_indices):\n",
    "        print(stacked_token_embeddings[torch.arange(0, target_indices.size(0)), target_indices[:, 1], -n:].shape)\n",
    "        print(torch.sum(stacked_token_embeddings[torch.arange(0, target_indices.size(0)), target_indices[:, 1], -n:], dim=1).shape)\n",
    "        return torch.sum(stacked_token_embeddings[torch.arange(0, target_indices.size(0)), target_indices[:, 1], -n:], dim=1)\n",
    "\n",
    "    return aggregate\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "def get_context_vectors(input_ids, attention_mask, target_mask):\n",
    "    # Ignore gradient to improve performance\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.to(device), attention_mask.to(device))\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "    # Extract model embeddings layer activations\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "    # Remove batches dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "    # Swap layer and token dimensions\n",
    "    token_embeddings = token_embeddings.permute(1, 0, 2)\n",
    "    \n",
    "    # Identify indices within encoded text to calculate context embeddings\n",
    "    target_indices = target_mask.to(device).nonzero()\n",
    "\n",
    "    # Use the sum of the last 4 embedding layers as an aggregation of context for the selected indices\n",
    "    stacked_token_embeddings = token_embeddings.repeat(torch.sum(target_mask), 1, 1, 1)\n",
    "    embedding_aggregate = cat_n_layers(4)(stacked_token_embeddings, target_indices)\n",
    "    thing = sum_n_layers(4)(stacked_token_embeddings, target_indices)\n",
    "\n",
    "    return embedding_aggregate\n",
    "\n",
    "test_vectors = torch.empty(0, 768).to(device)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for example in tqdm(dataset['validation'], desc='Collecting Contexts'):\n",
    "    input_ids = torch.tensor(example['input_ids'])\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    target_mask = torch.tensor(example['target_mask'])\n",
    "\n",
    "    embedding_aggregate = get_context_vectors(input_ids, attention_mask, target_mask)\n",
    "    #test_vectors = torch.cat((test_vectors, embedding_aggregate))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3, 6])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "b = a.repeat(2, 1, 1)\n",
    "print(b)\n",
    "\n",
    "indices = torch.tensor([[0, 0], [0, 1]])\n",
    "\n",
    "torch.sum(b[torch.arange(0, indices.size(0)), indices[:, 1], -1:], dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('gatenlp_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5e1f5b7c86f3a3638279a01f4f037ad1bf683427fdb20ed40b35537abd7abab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
